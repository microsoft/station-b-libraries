# -------------------------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License (MIT). See LICENSE in the repo root for license information.
# -------------------------------------------------------------------------------------------
"""ABEX pipeline can be run using this script, either locally or inside an Azure function.

Usage:

.. code-block:: bash

    # Run Bayesian Optimization locally
    python abex/scripts/run.py path-to-spec/spec.yml

* User issues "python scripts/run.py foobar.yml" on local machine
* "run" is called with the OptimizerConfig specified by foobar.yml
* "strategy" is generated by generate_strategy_function
* "strategy" is called, does BayesOpt etc, and writes out results.
"""
from typing import Optional, List

import param

import matplotlib

matplotlib.use("Agg")

from psbutils.psblogging import logging_to_stdout  # noqa: E402
from abex.common.generic_parsing import GenericConfig  # noqa: E402
from abex.optimizers.optimizer_base import OptimizerBase  # noqa: E402
from abex.settings import load_resolutions, OptimizerConfig  # noqa: E402

AML_EXPERIMENT_NAME = "station_b"


class RunConfig(GenericConfig):
    spec_file: str = param.String(None, doc="Name (to search for) or a path to a yaml spec file.")  # type: ignore
    # Arguments for the outer loop (running multiple runs with different seed)
    num_runs: int = param.Integer(10, bounds=(1, None), doc="Number of Optimization runs to execute.")  # type: ignore
    base_seed: int = param.Integer(0, doc="Minimum random-number-generator seed")  # type: ignore
    # Arguments for the inner loop (arguments defining a single run)
    num_iter: int = param.Integer(
        10, bounds=(1, None), doc="Number of Bayesian Optimization loop iterations to execute."
    )  # type: ignore
    plot_simulated_slices: bool = param.Boolean(  # type: ignore
        False, doc="Whether to plot slices of the simulator at the optimum found at the end."
    )
    submit_to_aml: bool = param.Boolean(False, doc="Whether to submit the script to run on Azure ML")  # type: ignore
    # Number of optimization runs per Azure ML Run (two quite different senses of "run" here).
    # Suppose we have a config with 4 resolutions (e.g. two "@" variables with two values each) and we ask for 15
    # optimization runs per resolution (num_runs=15).
    # Then: num_runs_per_aml_run=-1 means one AML Run will do all 4x15=60 optimization runs
    #       num_runs_per_aml_run=0  means there will be 4 AML Runs, doing 15 optimization runs each
    #       num_runs_per_aml_run=3  means there will be 4x(15/3)=20 AML Runs, doing 3 optimization runs each
    num_runs_per_aml_run: int = param.Integer(
        0,
        doc="If zero, submit one AML run per resolution, covering all its runs. "
        "If positive, submit multiple AML runs per resolution, each doing up to this many runs.",
    )  # type: ignore
    enable_multiprocessing: bool = param.Boolean(
        False,
        doc="Whether to enable multi-processing, allowing the individual runs with different seeds "
        "to proceed in parallel.",
    )  # type: ignore
    resolution_spec: str = param.String(
        None,
        doc="String of the form 'a2bb3' where @a and @bb are expansion variables occurring in the config "
        "(see expand.py for details). The values are indices (starting from 1). E.g. for an expansions "
        "`batch_size: ['@xx', 5, 10]` the string 'xx2' would select the config where batch_size == 10.",
    )  # type: ignore
    max_resolutions: int = param.Integer(
        10000,
        bounds=(1, None),
        doc="Maximum number of resolutions (expansions) for non-deterministic configs",
    )  # type: ignore
    aml_experiment: str = param.String(
        AML_EXPERIMENT_NAME,
        doc="Name of AzureML Experiment to submit run(s) to",
    )  # type: ignore
    output_dir: str = param.String("outputs", doc="Path to directory in which to store outputs")  # type: ignore


def main(arg_list: Optional[List[str]] = None) -> None:
    args = RunConfig().parse_args(args=arg_list)
    logging_to_stdout()
    for pair_list in load_resolutions(
        args.spec_file, seed=args.base_seed, num_runs=args.num_runs, config_class=OptimizerConfig
    ):
        for _, config in pair_list:
            # Decide which optimization strategy should be used
            optimizer = OptimizerBase.from_strategy(config, config.optimization_strategy)
            optimizer.run()


if __name__ == "__main__":  # pragma: no cover
    main()
